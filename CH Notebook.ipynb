{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUSINESS PROBLEM & UNDERSTANDING\n",
    "STAKEHOLDER:SPOTIFY\n",
    "PROBLEM: Spotify is launch a new Movie Divison. We are contracted Data Scientist tasked with  creating a reccomendation system for their movie division . We want to compete with other streaming platforms such as Netflix, Hulu, Amazon Prime. Since they are new to the market, they want to ensure that their Reccomendation System is accurate and reliable . This means creating a reliable reccomendation system that can provide users with movies and conetent taht tehy will actually enjoy thus keeping users on our platform.   \n",
    "\n",
    "TASK:\n",
    "Build a model that provides top 5 movie recommendations to a user, based on their ratings of other movies.\n",
    "The MovieLens dataset is a \"classic\" recommendation system dataset, that is used in numerous academic papers and machine learning proofs-of-concept. You will need to create the specific details about how the user will provide their ratings of other movies, in addition to formulating a more specific business problem within the general context of \"recommending movies\".\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import surprise\n",
    "from surprise.prediction_algorithms import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from surprise import Dataset, Reader\n",
    "from surprise import SVD\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import cross_validate, train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in datasets\n",
    "df_movies = pd.read_csv('data/movies.csv')\n",
    "df_links = pd.read_csv('data/links.csv')\n",
    "df_ratings = pd.read_csv('data/ratings.csv')\n",
    "df_tags = pd.read_csv('data/tags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#looking at each indivdual csv before merging.\n",
    "df_movies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataset contains links to each movie imdb and tmbd website ratings. Which is not applicable in the current scope of our business problem. \n",
    "df_links.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_links dataset contains links to each movie imdb and tmbd website ratings. Which is not applicable in the current scope of our business problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_tags.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for any movie duplicated in the dataset\n",
    "df_movies[df_movies['title'].duplicated() == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging Dataset to one Pandas Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# combining the Movies, Ratings, Tags Dataset. Not including Links dataset due to its non relevance to the business problem.\n",
    "movie_combo = pd.merge(df_movies, df_ratings, left_on='movieId', right_on='movieId', how='left')\n",
    "\n",
    "movie_combo.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there are missing values in rating and timestamps. Which will need to be addressed to ensure the algorithm will run sucessfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movie_combo.head() # now we have combined all the relevant datsets into one pandas database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movie_combo.drop(['genres'], axis=1) \n",
    "# We want to drop genres due to its relevance in our collaborative filtering process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to fill in the missing timestamp vales with the mode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling in missing timestamp values with the mode. \n",
    "movie_combo['timestamp'] = movie_combo['timestamp'].fillna(movie_combo['timestamp'].mode()[0])\n",
    "movie_combo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filling in missing rating values with the mode. \n",
    "movie_combo['rating'] = movie_combo['rating'].fillna(movie_combo['rating'].mode()[0])\n",
    "movie_combo.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next in our process  we want to convert the timestamp column to datetime format for our algorithm.\n",
    "First we have to convert timestamp from float type to interger. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting timsestamp column to integers\n",
    "movie_combo['timestamp'] = movie_combo['timestamp'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movie_combo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#checking for assurance\n",
    "movie_combo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_combo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# next is converting timestamp to datetime index format\n",
    "\n",
    "\n",
    "movie_combo['timestamp'] = movie_combo['timestamp'].apply(lambda t: datetime.utcfromtimestamp(t*1).strftime('%Y-%m-%d'))\n",
    "movie_combo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting duplicate titles to the lower of 'movieId' duplicates as the lower value had more user ratings in each instance.\n",
    "# This step was performed after merging the dateframes as we didn't want to lose data before the merge.\n",
    "\n",
    "for idx, row in movie_combo.iterrows():\n",
    "    # Emma (1996)\n",
    "    if  movie_combo.loc[idx,'movieId'] == 26958:\n",
    "        movie_combo.loc[idx,'movieId'] = 838\n",
    "    # War of the Worlds (2005)\n",
    "    elif movie_combo.loc[idx,'movieId'] == 64997:\n",
    "        movie_combo.loc[idx,'movieId'] = 34048\n",
    "    # Confessions of a Dangerous Mind (2002)\n",
    "    elif movie_combo.loc[idx,'movieId'] == 144606:\n",
    "        movie_combo.loc[idx,'movieId'] = 6003\n",
    "    # Eros (2004)\n",
    "    elif movie_combo.loc[idx,'movieId'] == 147002:\n",
    "        movie_combo.loc[idx,'movieId'] = 32600\n",
    "    # Saturn 3 (1980)\n",
    "    elif movie_combo.loc[idx,'movieId'] == 168358:\n",
    "        movie_combo.loc[idx,'movieId'] = 2851\n",
    "    else:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify corrections (Should be blank)\n",
    "movie_combo[(movie_combo['movieId'] == 26958 | 64997 | 144606 | 147002 | 168358)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we begin with our train test split and get into our process of modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reader = Reader(rating_scale =(0.5, 5) ) \n",
    "#df = Dataset.load_from_df(new_df,reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = movie_combo[['userId', 'movieId', 'rating']]\n",
    "reader = Reader(line_format='user item rating', sep=',',rating_scale=(0.5, 5))\n",
    "data = Dataset.load_from_df(data,reader =reader)\n",
    "# train-test-split\n",
    "#trainset, testset = train_test_split(data, test_size=.2)\n",
    "\n",
    "\n",
    "trainset, testset = surprise.model_selection.train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline/ Dummy Model  KNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline model with no paramater specified "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNNBasic().fit(trainset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_model = SVD().fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model = NMF().fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import KNNWithMeans\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "sim_options = {\n",
    "    \"name\": [\"msd\", \"cosine\",\"pearson\"],\n",
    "    \"min_support\": [3, 4],\n",
    "    \"user_based\": [False, True]\n",
    "}\n",
    "\n",
    "param_grid = {\"sim_options\": sim_options}\n",
    "\n",
    "gs = GridSearchCV(KNNWithMeans, param_grid, measures=[\"rmse\", \"mae\"], cv=3)\n",
    "gs.fit(data)\n",
    "\n",
    "print(gs.best_score[\"rmse\"])\n",
    "print(gs.best_params[\"rmse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs.best_score[\"mae\"])\n",
    "gs.best_params[\"mae\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_epochs\": [5, 10],\n",
    "    \"lr_all\": [0.002, 0.005],\n",
    "    \"reg_all\": [0.4, 0.6]\n",
    "}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=[\"rmse\", \"mae\"], cv=3)\n",
    "\n",
    "gs.fit(data)\n",
    "\n",
    "print(gs.best_score[\"rmse\"])\n",
    "print(gs.best_params[\"rmse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_neighbors\": [3,4,5],\n",
    "    \"leaf_size\": [3,4,5],\n",
    "    \"weights\": ['uniform', 'distance'],\n",
    "    \"p\": [1,2],\n",
    "    \"n_jobs\": [-1]\n",
    "}\n",
    "gs = GridSearchCV(KNNBasic, param_grid, measures=[\"rmse\", \"mae\"], cv=3)\n",
    "\n",
    "gs.fit(data)\n",
    "\n",
    "print(gs.best_score[\"rmse\"])\n",
    "print(gs.best_params[\"rmse\"])\n",
    "print(gs.best_score[\"mae\"])\n",
    "print(gs.best_params[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "knn_model.sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "knn_model.test(testset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "surprise.accuracy.mae(knn_model.test(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surprise.accuracy.rmse(knn_model.test(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surprise.accuracy.mae(svd_model.test(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surprise.accuracy.rmse(svd_model.test(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surprise.accuracy.mae(nmf_model.test(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surprise.accuracy.rmse(nmf_model.test(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model_tuned = KNNBasic({'n_neighbors': 3, 'leaf_size': 5, 'n_jobs': -1}).fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model_tuned.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model_tuned.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surprise.accuracy.mae(knn_model_tuned.test(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surprise.accuracy.rmse(knn_model_tuned.test(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Hot Encoding since Genre is a Categorical Column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical_vars = [\"genres\"]\n",
    "#one_hot_encoder = OneHotEncoder(sparse=False, drop = \"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder_vars_array = one_hot_encoder.fit_transform(new_df[categorical_vars])\n",
    "#encoder_feature_names = one_hot_encoder.get_feature_names(categorical_vars)\n",
    "#encoder_vars_df = pd.DataFrame(encoder_vars_array, columns = encoder_feature_names)\n",
    "#Data = pd.concat([new_df.reset_index(drop=True), encoder_vars_df.reset_index(drop=True)], axis = 1)\n",
    "#Data.drop(categorical_vars, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA and Visualizations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of users: ',len(Data.userId.unique()))\n",
    "print('Number of movie titles: ',len(Data.movieId.unique()))\n",
    "print('Number of ratings: ' ,Data.shape[0])\n",
    "print('Number of tags: ' ,Data.tag.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# groupby tags \n",
    "group = Data.groupby('tag').count()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "group[:10].rating.plot(kind='bar', figsize=(15,6))\n",
    "\n",
    "\n",
    "\n",
    "plt.title('Top 10 movie tags ');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top 10 re-occuring tags\n",
    "top_tags =Data.groupby(by=\"tag\").count().sort_values('movieId', ascending=False).userId.head(10)\n",
    "\n",
    "top_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of ratings\n",
    "Data.rating.plot.hist(bins=12)\n",
    "plt.xlabel('Rating')\n",
    "plt.title('Rating');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
